{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8NfAR-1MdyWA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Averaged Word2Vec Embedding â€” How It Works\n",
        "\n",
        "## What is Averaged Word2Vec?\n",
        "\n",
        "Averaged Word2Vec is a simple and effective technique for creating **sentence or document embeddings** by taking the **average of the Word2Vec vectors** of the words in the sentence.\n",
        "\n",
        "---\n",
        "\n",
        "## Sample Sentence\n",
        "\n",
        "Let's use the sentence:\n",
        "\n",
        "\"The cat sits on the mat\"\n",
        "\n"
      ],
      "metadata": {
        "id": "8VHj-VcKd2d7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Suppose our vocabulary includes:\n",
        "\n",
        "`[\"the\", \"cat\", \"sits\", \"on\", \"mat\"]`\n",
        "\n",
        "---\n",
        "\n",
        "## Step 1: Get Word2Vec Embeddings\n",
        "\n",
        "Assume each word is represented as a **2-dimensional Word2Vec vector** (for simplicity):\n",
        "\n",
        "| Word   | Word2Vec Vector         |\n",
        "|--------|-------------------------|\n",
        "| \"the\"  | $[0.1,\\ -0.3]$          |\n",
        "| \"cat\"  | $[0.7,\\ 0.4]$           |\n",
        "| \"sits\" | $[0.6,\\ 0.5]$           |\n",
        "| \"on\"   | $[0.0,\\ 0.2]$           |\n",
        "| \"mat\"  | $[-0.1,\\ 0.3]$          |\n",
        "\n",
        "---\n",
        "\n",
        "## Step 2: Tokenize the Sentence\n",
        "\n",
        "From `\"The cat sits on the mat\"`, we extract the tokens:\n",
        "\n",
        "[\"the\", \"cat\", \"sits\", \"on\", \"the\", \"mat\"]\n"
      ],
      "metadata": {
        "id": "Eyd1ByemeBDS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Note that \"the\" appears **twice**.\n",
        "\n",
        "---\n",
        "\n",
        "## Step 3: Compute Average Vector\n",
        "\n",
        "Let the sentence have $n$ words, each represented by a Word2Vec vector $\\vec{v}_i$.\n",
        "\n",
        "The **averaged sentence embedding** is calculated as:\n",
        "\n",
        "$$\n",
        "\\vec{v}_{\\text{sentence}} = \\frac{1}{n} \\sum_{i=1}^{n} \\vec{v}_i\n",
        "$$\n",
        "\n",
        "For our example:\n",
        "\n",
        "- \"the\" appears twice: $2 \\times [0.1,\\ -0.3] = [0.2,\\ -0.6]$\n",
        "- Add all vectors:\n",
        "\n",
        "$$\n",
        "\\vec{v}_{\\text{sum}} = [0.2, -0.6] + [0.7, 0.4] + [0.6, 0.5] + [0.0, 0.2] + [-0.1, 0.3]\n",
        "= [1.4, 0.8]\n",
        "$$\n",
        "\n",
        "- Total number of words = 6\n",
        "\n",
        "$$\n",
        "\\vec{v}_{\\text{avg}} = \\frac{[1.4,\\ 0.8]}{6} = [0.2333,\\ 0.1333]\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ” Final Sentence Embedding\n",
        "\n",
        "The averaged Word2Vec vector for the sentence:\n",
        "\n",
        "\n",
        "\"The cat sits on the mat\""
      ],
      "metadata": {
        "id": "dD40Jc2ieHyy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ukaAnX0VeP4U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "is:\n",
        "\n",
        "$$\n",
        "\\vec{v}_{\\text{sentence}} = [0.2333,\\ 0.1333]\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "## Why Use Averaged Word2Vec?\n",
        "\n",
        "| Advantage                     | Description                              |\n",
        "|------------------------------|------------------------------------------|\n",
        "| âœ… Simple                    | Easy to implement and compute            |\n",
        "| âœ… Fast                      | No training needed if Word2Vec is pretrained |\n",
        "| âœ… Captures meaning          | Aggregates word semantics                |\n",
        "| âŒ Loses structure            | Ignores word order and syntax            |\n",
        "| âŒ Equal weighting            | All words treated equally, including stopwords |\n",
        "\n",
        "---\n",
        "\n",
        "## When to Use\n",
        "\n",
        "- As a **baseline** for sentence/document representation\n",
        "- For tasks like:\n",
        "  - Text classification\n",
        "  - Document clustering\n",
        "  - Semantic similarity\n",
        "\n",
        "> ðŸ’¡ Averaged Word2Vec is a lightweight method that captures **overall meaning** without needing complex architectures.\n"
      ],
      "metadata": {
        "id": "wNRI04CYeRu0"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l0lx4n4beaRw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}