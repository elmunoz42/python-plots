{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40967b69-f95d-4e1c-85b7-2a3ca43d7229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " SUPER SIMPLE EXAMPLE NEURAL NETWORK \n",
      "\n",
      "STEP 1: Calculate input to hidden layer\n",
      "X (input features): [[0.5 0.1]]\n",
      "W1 (weights to hidden layer): \n",
      "[[0.15 0.2  0.25]\n",
      " [0.3  0.35 0.4 ]]\n",
      "b1 (biases for hidden layer): [0.1 0.1 0.1]\n",
      "\n",
      "Dot product calculation (X 路 W1):\n",
      "X[0,0] * W1[0,0] + X[0,1] * W1[1,0] = 0.5 * 0.15 + 0.1 * 0.3 = 0.105\n",
      "X[0,0] * W1[0,1] + X[0,1] * W1[1,1] = 0.5 * 0.2 + 0.1 * 0.35 = 0.135\n",
      "X[0,0] * W1[0,2] + X[0,1] * W1[1,2] = 0.5 * 0.25 + 0.1 * 0.4 = 0.165\n",
      "\n",
      "Adding biases:\n",
      "(0.105) + 0.1 = 0.20500000000000002\n",
      "(0.135) + 0.1 = 0.23500000000000001\n",
      "(0.165) + 0.1 = 0.265\n",
      "\n",
      "Final hidden_input: [[0.205 0.235 0.265]]\n",
      "\n",
      "STEP 2: Apply sigmoid activation function to get hidden layer output\n",
      "hidden_output = sigmoid(hidden_input): [[0.55107127 0.55848111 0.565865  ]]\n",
      "\n",
      "STEP 3: Calculate input to output layer\n",
      "hidden_output: [[0.55107127 0.55848111 0.565865  ]]\n",
      "W2 (weights to output layer): \n",
      "[[0.45]\n",
      " [0.5 ]\n",
      " [0.55]]\n",
      "b2 (bias for output layer): [0.1]\n",
      "\n",
      "Dot product calculation (hidden_output 路 W2):\n",
      "hidden_output[0,0] * W2[0,0] + hidden_output[0,1] * W2[1,0] + hidden_output[0,2] * W2[2,0] = \n",
      "0.551071269307342 * 0.45 + 0.5584811124381613 * 0.5 + 0.5658650028954816 * 0.55 = \n",
      "0.8384483789998995\n",
      "\n",
      "Adding bias: 0.8384483789998995 + 0.1 = 0.9384483789998995\n",
      "Final output_input: [[0.93844838]]\n",
      "\n",
      "STEP 4: Apply sigmoid activation function to get final output\n",
      "Final output = sigmoid(output_input): [[0.71878613]]\n",
      "\n",
      "NEURAL NETWORK SUMMARY:\n",
      "Final prediction result: [[0.71878613]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"\\n SUPER SIMPLE EXAMPLE NEURAL NETWORK \\n\")\n",
    "def sigmoid(x):\n",
    "    # Sigmoid activation function\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def simple_neural_network():\n",
    "    # Input features (2 features)\n",
    "    X = np.array([[0.5, 0.1]])  # Sample input\n",
    "    \n",
    "    # Initialize weights and biases\n",
    "    # Weights connecting input to hidden layer (2 input features x 3 hidden neurons)\n",
    "    W1 = np.array([[0.15, 0.20, 0.25],\n",
    "                   [0.30, 0.35, 0.40]])\n",
    "    \n",
    "    # Biases for hidden layer (3 neurons)\n",
    "    b1 = np.array([0.1, 0.1, 0.1])\n",
    "    \n",
    "    # Weights connecting hidden layer to output (3 hidden neurons x 1 output)\n",
    "    W2 = np.array([[0.45], \n",
    "                   [0.50], \n",
    "                   [0.55]])\n",
    "    \n",
    "    # Bias for output layer (1 neuron)\n",
    "    b2 = np.array([0.1])\n",
    "    \n",
    "    # FORWARD PROPAGATION - Broken down step by step\n",
    "    \n",
    "    # STEP 1: Calculate input to hidden layer\n",
    "    print(\"STEP 1: Calculate input to hidden layer\")\n",
    "    hidden_input = np.dot(X, W1) + b1\n",
    "    print(f\"X (input features): {X}\")\n",
    "    print(f\"W1 (weights to hidden layer): \\n{W1}\")\n",
    "    print(f\"b1 (biases for hidden layer): {b1}\")\n",
    "    \n",
    "    print(\"\\nDot product calculation (X 路 W1):\")\n",
    "    print(f\"X[0,0] * W1[0,0] + X[0,1] * W1[1,0] = {X[0,0]} * {W1[0,0]} + {X[0,1]} * {W1[1,0]} = {X[0,0] * W1[0,0] + X[0,1] * W1[1,0]}\")\n",
    "    print(f\"X[0,0] * W1[0,1] + X[0,1] * W1[1,1] = {X[0,0]} * {W1[0,1]} + {X[0,1]} * {W1[1,1]} = {X[0,0] * W1[0,1] + X[0,1] * W1[1,1]}\")\n",
    "    print(f\"X[0,0] * W1[0,2] + X[0,1] * W1[1,2] = {X[0,0]} * {W1[0,2]} + {X[0,1]} * {W1[1,2]} = {X[0,0] * W1[0,2] + X[0,1] * W1[1,2]}\")\n",
    "    \n",
    "    print(f\"\\nAdding biases:\")\n",
    "    print(f\"({X[0,0] * W1[0,0] + X[0,1] * W1[1,0]}) + {b1[0]} = {X[0,0] * W1[0,0] + X[0,1] * W1[1,0] + b1[0]}\")\n",
    "    print(f\"({X[0,0] * W1[0,1] + X[0,1] * W1[1,1]}) + {b1[1]} = {X[0,0] * W1[0,1] + X[0,1] * W1[1,1] + b1[1]}\")\n",
    "    print(f\"({X[0,0] * W1[0,2] + X[0,1] * W1[1,2]}) + {b1[2]} = {X[0,0] * W1[0,2] + X[0,1] * W1[1,2] + b1[2]}\")\n",
    "    \n",
    "    print(f\"\\nFinal hidden_input: {hidden_input}\")\n",
    "    \n",
    "    # STEP 2: Apply activation function to get hidden layer output\n",
    "    print(\"\\nSTEP 2: Apply sigmoid activation function to get hidden layer output\")\n",
    "    hidden_output = sigmoid(hidden_input)\n",
    "    print(f\"hidden_output = sigmoid(hidden_input): {hidden_output}\")\n",
    "    \n",
    "    # STEP 3: Calculate input to output layer\n",
    "    print(\"\\nSTEP 3: Calculate input to output layer\")\n",
    "    output_input = np.dot(hidden_output, W2) + b2\n",
    "    print(f\"hidden_output: {hidden_output}\")\n",
    "    print(f\"W2 (weights to output layer): \\n{W2}\")\n",
    "    print(f\"b2 (bias for output layer): {b2}\")\n",
    "    \n",
    "    print(\"\\nDot product calculation (hidden_output 路 W2):\")\n",
    "    print(f\"hidden_output[0,0] * W2[0,0] + hidden_output[0,1] * W2[1,0] + hidden_output[0,2] * W2[2,0] = \")\n",
    "    print(f\"{hidden_output[0,0]} * {W2[0,0]} + {hidden_output[0,1]} * {W2[1,0]} + {hidden_output[0,2]} * {W2[2,0]} = \")\n",
    "    dot_result = hidden_output[0,0] * W2[0,0] + hidden_output[0,1] * W2[1,0] + hidden_output[0,2] * W2[2,0]\n",
    "    print(f\"{dot_result}\")\n",
    "    \n",
    "    print(f\"\\nAdding bias: {dot_result} + {b2[0]} = {dot_result + b2[0]}\")\n",
    "    print(f\"Final output_input: {output_input}\")\n",
    "    \n",
    "    # STEP 4: Apply activation function to get final output\n",
    "    print(\"\\nSTEP 4: Apply sigmoid activation function to get final output\")\n",
    "    output = sigmoid(output_input)\n",
    "    print(f\"Final output = sigmoid(output_input): {output}\")\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Run the neural network\n",
    "result = simple_neural_network()\n",
    "print(\"\\nNEURAL NETWORK SUMMARY:\")\n",
    "print(f\"Final prediction result: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b16d2e-ce9d-447d-b469-26d9ae5fa0d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
